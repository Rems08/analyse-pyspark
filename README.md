# Analyse PySpark - Dataset Kaggle

![PySpark](https://img.shields.io/badge/PySpark-3.5+-orange.svg)
![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)

## ğŸ“– Description

Ce projet rÃ©alise une analyse complÃ¨te d'un dataset en utilisant **Apache PySpark**. Il dÃ©montre l'utilisation de PySpark pour l'exploration de donnÃ©es, les statistiques descriptives, les analyses par groupes, et les corrÃ©lations.

## ğŸ¯ Objectifs

- Charger et explorer un dataset type Kaggle
- RÃ©aliser des statistiques descriptives avec PySpark
- Analyser les donnÃ©es par groupes (dÃ©partements, genre)
- Calculer des corrÃ©lations entre variables
- GÃ©nÃ©rer des insights business

## ğŸ“Š Dataset

Le dataset utilisÃ© contient des donnÃ©es d'employÃ©s avec les informations suivantes:
- **id**: Identifiant unique de l'employÃ©
- **age**: Ã‚ge de l'employÃ©
- **gender**: Genre (M/F)
- **salary**: Salaire annuel
- **department**: DÃ©partement (IT, HR, Sales, Marketing)
- **experience_years**: AnnÃ©es d'expÃ©rience
- **satisfaction_score**: Score de satisfaction (0-10)
- **performance_rating**: Note de performance (0-5)

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- Java 8 ou supÃ©rieur (requis pour PySpark)

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

## ğŸ’» Utilisation

ExÃ©cutez le script d'analyse principal:

```bash
python analyse.py
```

## ğŸ“ˆ Analyses rÃ©alisÃ©es

Le script effectue les analyses suivantes:

1. **Exploration des donnÃ©es**
   - Structure du dataset
   - AperÃ§u des premiÃ¨res lignes
   - Statistiques descriptives

2. **Analyse par groupes**
   - Statistiques par dÃ©partement
   - Statistiques par genre
   - Distribution des employÃ©s

3. **CorrÃ©lations**
   - Salaire vs ExpÃ©rience
   - Satisfaction vs Performance
   - Ã‚ge vs ExpÃ©rience
   - Salaire vs Performance

4. **Analyses avancÃ©es**
   - EmployÃ©s Ã  haute performance
   - Analyse des fourchettes de salaires
   - Taux de satisfaction par dÃ©partement

5. **RÃ©sumÃ© et insights clÃ©s**
   - Vue d'ensemble du dataset
   - Insights business

## ğŸ“ Structure du projet

```
analyse-pyspark/
â”œâ”€â”€ analyse.py              # Script principal d'analyse
â”œâ”€â”€ data/
â”‚   â””â”€â”€ employee_data.csv   # Dataset d'exemple
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ README.md              # Documentation
â””â”€â”€ .gitignore             # Fichiers Ã  ignorer
```

## ğŸ” Exemple de sortie

Le script gÃ©nÃ¨re une sortie complÃ¨te avec:
- Statistiques descriptives des variables numÃ©riques
- Tableaux d'agrÃ©gation par dÃ©partement et genre
- CorrÃ©lations entre variables
- Insights clÃ©s sur les donnÃ©es

## ğŸ“ MÃ©thodologie

L'analyse utilise les capacitÃ©s distribuÃ©es de PySpark pour:
- Traiter efficacement de grands volumes de donnÃ©es
- Effectuer des agrÃ©gations et groupements
- Calculer des statistiques en parallÃ¨le
- Optimiser les performances avec le lazy evaluation

## ğŸ› ï¸ Technologies utilisÃ©es

- **PySpark**: Framework de traitement distribuÃ©
- **Python**: Langage de programmation
- **Pandas**: Manipulation de donnÃ©es (optionnel)
- **Matplotlib/Seaborn**: Visualisations (optionnel)

## ğŸ“š Ressources

- [Documentation PySpark](https://spark.apache.org/docs/latest/api/python/)
- [Apache Spark](https://spark.apache.org/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)

## ğŸ‘¤ Auteur

Rems08

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.