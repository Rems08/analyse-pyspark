# Analyse PySpark - Dataset Kaggle

![PySpark](https://img.shields.io/badge/PySpark-3.5+-orange.svg)
![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.40+-red.svg)

## ğŸ“– Description

Ce projet rÃ©alise une analyse complÃ¨te d'un dataset en utilisant **Apache PySpark**. Il dÃ©montre l'utilisation de PySpark pour l'exploration de donnÃ©es, les statistiques descriptives, les analyses par groupes, et les corrÃ©lations.

**Nouveau** : Une interface interactive **Streamlit** permet de visualiser et d'explorer les donnÃ©es de maniÃ¨re conviviale.

## ğŸ¯ Objectifs

- Charger et explorer un dataset type Kaggle
- RÃ©aliser des statistiques descriptives avec PySpark
- Analyser les donnÃ©es par groupes (dÃ©partements, genre)
- Calculer des corrÃ©lations entre variables
- GÃ©nÃ©rer des insights business
- **Visualiser les donnÃ©es avec une interface Streamlit interactive**

## ğŸ“Š Dataset

Le dataset utilisÃ© contient des donnÃ©es d'employÃ©s avec les informations suivantes:
- **id**: Identifiant unique de l'employÃ©
- **age**: Ã‚ge de l'employÃ©
- **gender**: Genre (M/F)
- **salary**: Salaire annuel
- **department**: DÃ©partement (IT, HR, Sales, Marketing)
- **experience_years**: AnnÃ©es d'expÃ©rience
- **satisfaction_score**: Score de satisfaction (0-10)
- **performance_rating**: Note de performance (0-5)

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- Java 17 (requis pour PySpark)
- [Mise](https://mise.jdx.dev/) (gestionnaire de tÃ¢ches)
- Apache Spark (optionnel, pour le mode cluster)

### Installation des dÃ©pendances

```bash
# Avec mise (recommandÃ©)
mise run install

# Ou avec pip
pip install -r requirements.txt
```

### Installation de Spark (optionnel)

Pour utiliser le mode cluster avec Master/Workers :

```bash
# macOS avec Homebrew
brew install openjdk@17
brew install apache-spark

# Voir les instructions complÃ¨tes
mise run install-spark
```

## ğŸ’» Utilisation

### ğŸŒ Interface Streamlit (recommandÃ©)

Lancez l'application Streamlit pour une exploration interactive des donnÃ©es :

```bash
# Avec mise
mise run streamlit

# Ou directement
streamlit run streamlit_app.py
```

L'interface Streamlit offre :
- **ğŸ“ˆ Vue d'ensemble** : MÃ©triques clÃ©s et graphiques de synthÃ¨se
- **ğŸ¢ Analyse par DÃ©partement** : Statistiques dÃ©taillÃ©es par dÃ©partement
- **ğŸ“Š Distributions** : Histogrammes et scatter plots interactifs
- **ğŸ”— CorrÃ©lations** : Matrice de corrÃ©lation et heatmap
- **ğŸ“‹ DonnÃ©es brutes** : Exploration et export des donnÃ©es

**Filtres disponibles** :
- DÃ©partement
- Genre
- Tranche d'Ã¢ge
- Tranche de salaire

### Mode simple (local)

```bash
# Avec mise
mise run analyse

# Ou directement
python analyse.py
```

### Mode interactif

```bash
# Shell PySpark
mise run pyspark-shell

# Jupyter Notebook
mise run notebook
```

## ğŸ¬ DÃ©mo : Cluster Spark avec Master et Workers

Cette section dÃ©crit la procÃ©dure complÃ¨te pour dÃ©marrer un cluster Spark local avec un Master et plusieurs Workers, idÃ©al pour une dÃ©monstration du traitement distribuÃ©.

### Ã‰tape 1 : VÃ©rifier les prÃ©requis

```bash
# VÃ©rifier que Java est installÃ©
java -version

# VÃ©rifier que Spark est installÃ©
spark-shell --version

# Afficher les infos du projet
mise run info
```

### Ã‰tape 2 : DÃ©marrer le cluster Spark

**Option A : DÃ©marrage automatique (recommandÃ©)**

```bash
# DÃ©marrer le cluster complet (1 Master + 2 Workers)
mise run spark-cluster-start
```

**Option B : DÃ©marrage manuel Ã©tape par Ã©tape**

```bash
# Terminal 1 : DÃ©marrer le Master
mise run spark-master-start

# Terminal 2 : DÃ©marrer le Worker 1
mise run spark-worker-start

# Terminal 3 : DÃ©marrer un second Worker (optionnel)
mise run spark-worker-start
```

### Ã‰tape 3 : VÃ©rifier le statut du cluster

```bash
# Afficher le statut
mise run spark-cluster-status
```

**Interfaces Web disponibles :**

| Composant | URL |
|-----------|-----|
| ğŸ–¥ï¸ Master UI | http://localhost:8080 |
| ğŸ‘· Worker 1 UI | http://localhost:8081 |
| ğŸ‘· Worker 2 UI | http://localhost:8082 |

### Ã‰tape 4 : ExÃ©cuter l'analyse sur le cluster

```bash
# Soumettre le job au cluster
mise run analyse-cluster
```

Ou utiliser le shell PySpark connectÃ© au cluster :

```bash
mise run pyspark-shell-cluster
```

### Ã‰tape 5 : Observer l'exÃ©cution

1. Ouvrez http://localhost:8080 dans votre navigateur
2. Observez les **Workers** enregistrÃ©s
3. Cliquez sur **Running Applications** pour voir le job en cours
4. Explorez les **Executors** et les **Stages**

### Ã‰tape 6 : ArrÃªter le cluster

```bash
# ArrÃªter tout le cluster
mise run spark-cluster-stop
```

### ğŸ“‹ RÃ©sumÃ© des commandes Mise pour le cluster

| Commande | Description |
|----------|-------------|
| `mise run spark-cluster-start` | ğŸŒŸ DÃ©marrer Master + 2 Workers |
| `mise run spark-cluster-stop` | ğŸ›‘ ArrÃªter tout le cluster |
| `mise run spark-cluster-status` | ğŸ“Š Voir le statut du cluster |
| `mise run spark-master-start` | ğŸš€ DÃ©marrer uniquement le Master |
| `mise run spark-master-stop` | ğŸ›‘ ArrÃªter le Master |
| `mise run spark-worker-start` | ğŸ‘· DÃ©marrer un Worker |
| `mise run spark-worker-stop` | ğŸ›‘ ArrÃªter les Workers |
| `mise run analyse-cluster` | ğŸ“Š ExÃ©cuter l'analyse sur le cluster |
| `mise run pyspark-shell-cluster` | ğŸ Shell connectÃ© au cluster |

### ğŸ’¡ Tips pour la dÃ©mo

1. **Ouvrez le Master UI** avant de lancer le job pour voir les Workers s'enregistrer
2. **Utilisez plusieurs terminaux** pour montrer le dÃ©marrage sÃ©quentiel
3. **Montrez les logs** dans la console du Worker pendant l'exÃ©cution
4. **Comparez les performances** entre mode local et mode cluster

## ğŸ–¥ï¸ Mode Master/Worker sur plusieurs terminaux

Cette section explique comment configurer un cluster Spark avec votre PC comme **Master** et lancer des **Workers** depuis d'autres terminaux (ou machines).

### Architecture du cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MACHINE MASTER                           â”‚
â”‚                    (Votre PC principal)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Spark Master                                â”‚   â”‚
â”‚  â”‚  â€¢ Coordonne le cluster                                  â”‚   â”‚
â”‚  â”‚  â€¢ WebUI: http://<IP>:8080                              â”‚   â”‚
â”‚  â”‚  â€¢ URL: spark://<IP>:7077                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                 â”‚                 â”‚
            â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Worker 1    â”‚ â”‚   Worker 2    â”‚ â”‚   Worker N    â”‚
    â”‚   Terminal 2  â”‚ â”‚   Terminal 3  â”‚ â”‚  Autre machineâ”‚
    â”‚   Port 8081   â”‚ â”‚   Port 8082   â”‚ â”‚   Port 8081   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PrÃ©requis

Sur **chaque machine** (Master et Workers) :

```bash
# 1. Java 17
brew install openjdk@17

# 2. Apache Spark
brew install apache-spark

# 3. Configurer Java
export JAVA_HOME="/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home"
```

### Ã‰tape 1 : Obtenir l'adresse IP du Master

Sur la machine qui sera le Master :

```bash
# Afficher votre IP
mise run get-ip

# Sortie exemple:
# ğŸ“ Adresses IP locales:
#    IPv4 (WiFi): 192.168.1.42
```

**Notez cette IP**, vous en aurez besoin pour connecter les Workers.

### Ã‰tape 2 : DÃ©marrer le Master (Terminal 1)

```bash
# Terminal 1 - Machine Master
mise run spark-master-network
```

Sortie attendue :
```
ğŸš€ DÃ©marrage du Spark Master en mode rÃ©seau...

ğŸ“ Configuration:
   IP du Master: 192.168.1.42
   Port Spark: 7077
   Port WebUI: 8080

ğŸ”— URL de connexion pour les Workers:
   spark://192.168.1.42:7077

ğŸŒ Interface Web (accessible depuis le rÃ©seau):
   http://192.168.1.42:8080
```

**Gardez ce terminal ouvert** - le Master doit rester actif.

### Ã‰tape 3 : Connecter un Worker (Terminal 2)

Ouvrez un **nouveau terminal** (sur la mÃªme machine ou une autre) :

```bash
# Terminal 2 - Worker 1
MASTER_IP=192.168.1.42 mise run spark-worker-connect
```

> ğŸ’¡ Remplacez `192.168.1.42` par l'IP de votre Master.

### Ã‰tape 4 : Ajouter d'autres Workers (Terminaux 3, 4, ...)

```bash
# Terminal 3 - Worker 2 (mÃªme machine, port diffÃ©rent)
MASTER_IP=192.168.1.42 WORKER_PORT=8082 mise run spark-worker-connect-custom

# Terminal 4 - Worker 3 (autre machine)
MASTER_IP=192.168.1.42 mise run spark-worker-connect
```

### Configuration personnalisÃ©e des Workers

Vous pouvez ajuster les ressources de chaque Worker :

```bash
MASTER_IP=192.168.1.42 \
WORKER_CORES=4 \
WORKER_MEM=4g \
WORKER_PORT=8083 \
mise run spark-worker-connect-custom
```

| Variable | Description | Valeur par dÃ©faut |
|----------|-------------|-------------------|
| `MASTER_IP` | IP du Master Spark | (requis) |
| `WORKER_CORES` | Nombre de cores CPU | 2 |
| `WORKER_MEM` | MÃ©moire allouÃ©e | 2g |
| `WORKER_PORT` | Port WebUI du Worker | 8081 |

### Ã‰tape 5 : VÃ©rifier le cluster

1. **Interface Web Master** : http://192.168.1.42:8080
   - Voir tous les Workers connectÃ©s
   - Ã‰tat des ressources (cores, mÃ©moire)
   - Applications en cours

2. **Interface Web Workers** :
   - Worker 1 : http://localhost:8081
   - Worker 2 : http://localhost:8082

3. **Ligne de commande** :
   ```bash
   mise run spark-cluster-status
   ```

### Ã‰tape 6 : ExÃ©cuter une analyse sur le cluster

```bash
# Soumettre l'analyse au cluster rÃ©seau
MASTER_IP=192.168.1.42 mise run analyse-network
```

Ou utilisez le shell PySpark connectÃ© :

```bash
# Shell interactif
MASTER_IP=192.168.1.42 mise run pyspark-shell-cluster
```

### Exemple complet : 3 Terminaux

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERMINAL 1 : Master
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
mise run spark-master-network
# â†’ Gardez ouvert, notez l'IP (ex: 192.168.1.42)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERMINAL 2 : Worker 1
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MASTER_IP=192.168.1.42 mise run spark-worker-connect
# â†’ Gardez ouvert

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERMINAL 3 : Worker 2 (port diffÃ©rent)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MASTER_IP=192.168.1.42 WORKER_PORT=8082 mise run spark-worker-connect-custom
# â†’ Gardez ouvert

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERMINAL 4 : ExÃ©cuter l'analyse
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MASTER_IP=192.168.1.42 mise run analyse-network
```

### ğŸ“‹ Commandes rÃ©seau

| Commande | Description |
|----------|-------------|
| `mise run get-ip` | ğŸŒ Afficher l'IP de la machine |
| `mise run spark-master-network` | ğŸš€ DÃ©marrer le Master (mode rÃ©seau) |
| `MASTER_IP=<ip> mise run spark-worker-connect` | ğŸ‘· Connecter un Worker |
| `MASTER_IP=<ip> mise run spark-worker-connect-custom` | ğŸ‘· Worker avec config personnalisÃ©e |
| `MASTER_IP=<ip> mise run analyse-network` | ğŸ“Š Analyse sur cluster rÃ©seau |

### RÃ©solution des problÃ¨mes

#### âŒ Le Worker ne se connecte pas au Master

1. **VÃ©rifiez le pare-feu** : Le port 7077 doit Ãªtre ouvert
   ```bash
   # macOS - Autoriser les connexions
   sudo /usr/libexec/ApplicationFirewall/socketfilterfw --add /opt/homebrew/opt/apache-spark/libexec/bin/spark-class
   ```

2. **VÃ©rifiez la connectivitÃ©** :
   ```bash
   # Depuis le Worker, tester la connexion
   nc -zv 192.168.1.42 7077
   ```

3. **VÃ©rifiez les logs** : Les erreurs s'affichent dans le terminal du Worker

#### âŒ Erreur "Connection refused"

- Assurez-vous que le Master est dÃ©marrÃ© **avant** les Workers
- VÃ©rifiez que l'IP du Master est correcte
- Les machines doivent Ãªtre sur le mÃªme rÃ©seau

#### âŒ Workers non visibles dans l'UI

- Attendez quelques secondes aprÃ¨s le dÃ©marrage
- RafraÃ®chissez l'interface Web du Master

## ğŸ“ˆ Analyses rÃ©alisÃ©es

Le script effectue les analyses suivantes:

1. **Exploration des donnÃ©es**
   - Structure du dataset
   - AperÃ§u des premiÃ¨res lignes
   - Statistiques descriptives

2. **Analyse par groupes**
   - Statistiques par dÃ©partement
   - Statistiques par genre
   - Distribution des employÃ©s

3. **CorrÃ©lations**
   - Salaire vs ExpÃ©rience
   - Satisfaction vs Performance
   - Ã‚ge vs ExpÃ©rience
   - Salaire vs Performance

4. **Analyses avancÃ©es**
   - EmployÃ©s Ã  haute performance
   - Analyse des fourchettes de salaires
   - Taux de satisfaction par dÃ©partement

5. **RÃ©sumÃ© et insights clÃ©s**
   - Vue d'ensemble du dataset
   - Insights business

## ğŸ“ Structure du projet

```
analyse-pyspark/
â”œâ”€â”€ analyse.py              # Script principal d'analyse
â”œâ”€â”€ data/
â”‚   â””â”€â”€ employee_data.csv   # Dataset d'exemple
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ README.md              # Documentation
â””â”€â”€ .gitignore             # Fichiers Ã  ignorer
```

## ğŸ” Exemple de sortie

Le script gÃ©nÃ¨re une sortie complÃ¨te avec:
- Statistiques descriptives des variables numÃ©riques
- Tableaux d'agrÃ©gation par dÃ©partement et genre
- CorrÃ©lations entre variables
- Insights clÃ©s sur les donnÃ©es

## ğŸ“ MÃ©thodologie

L'analyse utilise les capacitÃ©s distribuÃ©es de PySpark pour:
- Traiter efficacement de grands volumes de donnÃ©es
- Effectuer des agrÃ©gations et groupements
- Calculer des statistiques en parallÃ¨le
- Optimiser les performances avec le lazy evaluation

## ğŸ› ï¸ Technologies utilisÃ©es

- **PySpark**: Framework de traitement distribuÃ©
- **Python**: Langage de programmation
- **Pandas**: Manipulation de donnÃ©es (optionnel)
- **Matplotlib/Seaborn**: Visualisations (optionnel)

## ğŸ“š Ressources

- [Documentation PySpark](https://spark.apache.org/docs/latest/api/python/)
- [Apache Spark](https://spark.apache.org/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)

## ğŸ‘¤ Auteur

Rems08

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.